{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3beb4c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "# Set the desired count for data augmentation\n",
    "desired_augmentation_count = 3000\n",
    "\n",
    "# Set the desired train-test-validation ratios\n",
    "train_ratio = 0.7\n",
    "test_ratio = 0.2\n",
    "val_ratio = 0.1\n",
    "\n",
    "# Specify the paths\n",
    "dataset_path = r'D:\\SETU Assignments\\Dissertation\\Dataset\\Data'\n",
    "output_folder = r'D:\\SETU Assignments\\Dissertation\\Dataset\\ProcessedDS'\n",
    "\n",
    "# Define the classes and their corresponding counts\n",
    "classes = [\n",
    "    'Bacterial Blight', 'Bacterial Streak', 'Brown Spot', 'Healthy', 'Hispa',\n",
    "    'Leaf Blast', 'Leaf Scald', 'Leaf Smut', 'Neck Blast', 'Tungro'\n",
    "]\n",
    "class_counts = {\n",
    "    'Bacterial Blight': 1833,\n",
    "    'Bacterial Streak': 628,\n",
    "    'Brown Spot': 5041,\n",
    "    'Healthy': 8294,\n",
    "    'Hispa': 3572,\n",
    "    'Leaf Blast': 6666,\n",
    "    'Leaf Scald': 438,\n",
    "    'Leaf Smut': 80,\n",
    "    'Neck Blast': 2000,\n",
    "    'Tungro': 360\n",
    "}\n",
    "\n",
    "# Create train, test, and validation directories\n",
    "train_path = os.path.join(output_folder, 'train')\n",
    "test_path = os.path.join(output_folder, 'test')\n",
    "val_path = os.path.join(output_folder, 'val')\n",
    "os.makedirs(train_path, exist_ok=True)\n",
    "os.makedirs(test_path, exist_ok=True)\n",
    "os.makedirs(val_path, exist_ok=True)\n",
    "\n",
    "# Perform data augmentation and split dataset for each class\n",
    "for class_name in classes:\n",
    "    class_folder = os.path.join(dataset_path, class_name)\n",
    "    output_class_folder = os.path.join(output_folder, class_name)\n",
    "    os.makedirs(output_class_folder, exist_ok=True)\n",
    "    \n",
    "    # Check the number of images in the class folder\n",
    "    image_count = len(os.listdir(class_folder))\n",
    "    \n",
    "    # Perform data augmentation if the count is less than the desired count\n",
    "    if image_count < desired_augmentation_count:\n",
    "        # Calculate the number of images to be augmented\n",
    "        augmentation_count = desired_augmentation_count - image_count\n",
    "        \n",
    "        # Augment the images by randomly selecting and copying existing images\n",
    "        for i in range(augmentation_count):\n",
    "            source_image = random.choice(os.listdir(class_folder))\n",
    "            source_image_path = os.path.join(class_folder, source_image)\n",
    "            target_image_path = os.path.join(output_class_folder, f'augmented_{i+1}.jpg')\n",
    "            shutil.copy(source_image_path, target_image_path)\n",
    "    \n",
    "    # Move the original and augmented images to train, test, and validation sets\n",
    "    all_files = os.listdir(output_class_folder)\n",
    "    random.shuffle(all_files)\n",
    "    train_count = int(train_ratio * len(all_files))\n",
    "    test_count = int(test_ratio * len(all_files))\n",
    "    val_count = int(val_ratio * len(all_files))\n",
    "    \n",
    "    train_files = all_files[:train_count]\n",
    "    test_files = all_files[train_count:train_count+test_count]\n",
    "    val_files = all_files[train_count+test_count:]\n",
    "    \n",
    "    for file in train_files:\n",
    "        src = os.path.join(output_class_folder, file)\n",
    "        dst = os.path.join(train_path, file)\n",
    "        shutil.copy(src, dst)\n",
    "    \n",
    "    for file in test_files:\n",
    "        src = os.path.join(output_class_folder, file)\n",
    "        dst = os.path.join(test_path, file)\n",
    "        shutil.copy(src, dst)\n",
    "    \n",
    "    for file in val_files:\n",
    "        src = os.path.join(output_class_folder, file)\n",
    "        dst = os.path.join(val_path, file)\n",
    "        shutil.copy(src, dst)\n",
    "\n",
    "print(\"Data augmentation and dataset splitting completed successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7eaa5f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset splitting completed successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "# Specify the paths\n",
    "dataset_path = r'D:\\SETU Assignments\\Dissertation\\Dataset\\Data'\n",
    "output_folder = r'D:\\SETU Assignments\\Dissertation\\Dataset\\ProcessedDS'\n",
    "\n",
    "# Create the train, test, and val folders\n",
    "train_path = os.path.join(output_folder, 'train')\n",
    "test_path = os.path.join(output_folder, 'test')\n",
    "val_path = os.path.join(output_folder, 'val')\n",
    "os.makedirs(train_path, exist_ok=True)\n",
    "os.makedirs(test_path, exist_ok=True)\n",
    "os.makedirs(val_path, exist_ok=True)\n",
    "\n",
    "# Define the train, test, and val ratios\n",
    "train_ratio = 0.7\n",
    "test_ratio = 0.2\n",
    "val_ratio = 0.1\n",
    "\n",
    "# Specify the classes to be used for splitting\n",
    "classes = [\n",
    "    'Bacterial Blight', 'Bacterial Streak', 'Brown Spot', 'Healthy', 'Hispa',\n",
    "    'Leaf Blast', 'Leaf Scald', 'Leaf Smut', 'Neck Blast', 'Tungro'\n",
    "]\n",
    "\n",
    "for class_name in classes:\n",
    "    class_folder = os.path.join(dataset_path, class_name)\n",
    "\n",
    "    # Get the list of images for the class\n",
    "    images = os.listdir(class_folder)\n",
    "\n",
    "    # Shuffle the images\n",
    "    random.shuffle(images)\n",
    "\n",
    "    # Calculate the number of images for each split\n",
    "    total_images = len(images)\n",
    "    train_count = int(total_images * train_ratio)\n",
    "    test_count = int(total_images * test_ratio)\n",
    "    val_count = total_images - train_count - test_count\n",
    "\n",
    "    # Split the images into train, test, and val sets\n",
    "    train_images = images[:train_count]\n",
    "    test_images = images[train_count:train_count + test_count]\n",
    "    val_images = images[train_count + test_count:]\n",
    "\n",
    "    # Move the images to the respective folders\n",
    "    for image in train_images:\n",
    "        src = os.path.join(class_folder, image)\n",
    "        dst = os.path.join(train_path, class_name, image)\n",
    "        os.makedirs(os.path.dirname(dst), exist_ok=True)\n",
    "        shutil.copy(src, dst)\n",
    "\n",
    "    for image in test_images:\n",
    "        src = os.path.join(class_folder, image)\n",
    "        dst = os.path.join(test_path, class_name, image)\n",
    "        os.makedirs(os.path.dirname(dst), exist_ok=True)\n",
    "        shutil.copy(src, dst)\n",
    "\n",
    "    for image in val_images:\n",
    "        src = os.path.join(class_folder, image)\n",
    "        dst = os.path.join(val_path, class_name, image)\n",
    "        os.makedirs(os.path.dirname(dst), exist_ok=True)\n",
    "        shutil.copy(src, dst)\n",
    "\n",
    "print(\"Dataset splitting completed successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468a4720",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a84abc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f822ec50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d6d059",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d17536",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb04edbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56652a7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ffa402",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10200bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306b110f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
